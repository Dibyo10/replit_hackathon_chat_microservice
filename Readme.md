# How does this service function?

This microservice lets your team design APIs just by talking â€” then automatically generates production-grade artifacts like:

- `openapi.yaml` (API Spec)
- `rules.md` (Design Conventions)
- `schema.json` (Data Model Definitions)

Itâ€™s basically an **AI API architect**:  
It forces clarity, enforces a Contract-First workflow, and produces all files ready for backend integration.

---

## ğŸ§  What This Service Does

Instead of manually writing OpenAPI specs, your team can chat with the AI assistant (powered by Gemini).  
It asks questions like:

- â€œWhat are your entities?â€
- â€œHow will authentication work?â€
- â€œWhich fields must be unique?â€

And once youâ€™re done â€” you type `GENERATE`, and the bot spits out all the files you need.

---

## âš™ï¸ TL;DR Flow

- Frontend connects to `/api/chat/stream`
- You chat with the Gemini Flash model (it remembers the session)
- Once you type `GENERATE`, the backend switches to Gemini 2.5 Pro
- It generates:
    - `openapi.yaml`
    - `rules.md`
    - `schema.json`
- You or your backend can fetch each file separately:
    - `/api/files/{session_id}/openapi`
    - `/api/files/{session_id}/rules`
    - `/api/files/{session_id}/schema`

> ğŸ’¡ **Think ChatGPT â€” but instead of random text, it gives you a clean, validated OpenAPI contract.**

---

## ğŸ§© System Overview

```
Frontend (test.html / real app)
        â”‚
        â–¼
[ FastAPI Backend ]
â”œâ”€â”€ /api/chat/stream       â†’  Gemini 1.5 Flash (streaming chat)
â”œâ”€â”€ /api/generate          â†’  Gemini 2.5 Pro (file generation)
â”œâ”€â”€ /api/files/{id}/openapi
â”œâ”€â”€ /api/files/{id}/rules
â””â”€â”€ /api/files/{id}/schema
        â”‚
        â–¼
[ Redis Storage (persistent sessions) ]
```

---

## ğŸ§± Core Concepts

| Concept        | Meaning                                                                                       |
| -------------- | -------------------------------------------------------------------------------------------- |
| Session        | A userâ€™s chat context, saved in Redis (not memory). Contains the full chat + generated files.|
| Chat Phase     | You and the bot define your API contract through conversation.                               |
| Generate Phase | Once you type GENERATE, backend switches models to produce artifacts.                        |
| Artifacts      | `openapi.yaml`, `rules.md`, and `schema.json` â€” all generated by Gemini Pro.                 |
| Redis Storage  | Keeps sessions persistent even if the server restarts. Shared across instances.              |

---

## ğŸ§© Directory Structure

```
app/
 â”œâ”€â”€ main.py                     # FastAPI entrypoint
 â”œâ”€â”€ core/
 â”‚   â”œâ”€â”€ config.py               # Environment + model config
 â”‚   â”œâ”€â”€ redis_client.py         # Redis connection setup
 â”‚   â””â”€â”€ prompts.py              # System persona prompt (Contract-first architect)
 â”œâ”€â”€ models/
 â”‚   â””â”€â”€ schemas.py              # Pydantic models for requests/responses
 â”œâ”€â”€ routers/
 â”‚   â”œâ”€â”€ chat.py                 # /api/chat/stream (Gemini Flash chat)
 â”‚   â””â”€â”€ generation.py           # /api/generate + /api/files/*
 â”œâ”€â”€ services/
 â”‚   â”œâ”€â”€ gemini_service.py       # Gemini API wrappers
 â”‚   â””â”€â”€ session_manager.py      # Session handling (Redis-backed)
 â””â”€â”€ utils/
     â””â”€â”€ parser.py               # Extracts files from Geminiâ€™s response
```

---

## ğŸ’¬ Conversation Workflow

### 1. Chat Phase

You describe your system.

Example:
```
User: Weâ€™re building an inventory management API.
Bot: Please define the core entities â€” Products, Warehouses, or both?
User: Products and Warehouses. UUID IDs, JWT Auth.
```

â†’ Stored in `session.history` (in Redis).

---

### 2. Trigger Generation

When you type:
```
GENERATE
```
The bot replies:
```
Ready to generate. Call /api/generate
```

Your frontend or backend now calls the generation endpoint.

---

### 3. Generation Phase

Backend sends the entire conversation to Gemini 2.5 Pro, which generates

```
---FILE: openapi.yaml---
...
---FILE: rules.md---
...
---FILE: schema.json---
...
```

Then parses and saves them in Redis under your session ID.

---

### 4. File Access Phase

You can now fetch them individually:

| Endpoint                           | Returns          |
| ----------------------------------- | --------------- |
| `/api/files/{session_id}/openapi`   | OpenAPI YAML    |
| `/api/files/{session_id}/rules`     | Rules Markdown  |
| `/api/files/{session_id}/schema`    | JSON Schema     |

---

## ğŸ§‘â€ğŸ’» How To Run It Locally

1. **Clone the repo**
    ```sh
    git clone https://github.com/<your-org>/<repo-name>.git
    cd replit_hackathon
    ```

2. **Create .env**
    ```
    GEMINI_API_KEY=your_google_gemini_api_key
    GEMINI_CHAT_MODEL=gemini-1.5-flash
    GEMINI_GENERATE_MODEL=gemini-2.5-pro
    REDIS_HOST=localhost
    REDIS_PORT=6379
    ```

3. **Install dependencies**
    ```sh
    pip install -r requirements.txt
    ```

4. **Start Redis (if not already running)**
    ```sh
    brew services start redis
    redis-cli ping
    # should return: PONG
    ```

5. **Start the FastAPI server**
    ```sh
    uvicorn app.main:app --reload --port 8000
    ```

6. **Open the test UI**  
   In your browser:
    ```
    frontend/test.html
    ```

---

## ğŸ§© API Endpoints

#### 1ï¸âƒ£ POST `/api/chat/stream`
- Handles streaming chat messages with Gemini Flash.
- **Request:**
    ```json
    {
      "session_id": "abc123",
      "message": "Define a task management API"
    }
    ```
- **Response (streamed):**
    ```
    Bot: Define your core entities â€” Task, User, Project?
    Bot: What is your ID format?
    [STREAM_END]
    ```

#### 2ï¸âƒ£ POST `/api/generate`
- Triggers file generation using Gemini 2.5 Pro.
- **Request:**
    ```json
    { "session_id": "abc123" }
    ```
- **Response:**
    ```json
    {
      "openapi_yaml": "openapi: 3.0.1...",
      "rules_md": "# API Rules...",
      "schema_json": "{...}"
    }
    ```

#### 3ï¸âƒ£ `/api/files/{session_id}/openapi`
- Returns openapi.yaml (raw YAML).

#### 4ï¸âƒ£ `/api/files/{session_id}/rules`
- Returns rules.md (Markdown).

#### 5ï¸âƒ£ `/api/files/{session_id}/schema`
- Returns schema.json (JSON Schema).

---

## ğŸ¨ Frontend Dev Guide

If youâ€™re the frontend dev, your workflow:

- Call `/api/chat/stream` â†’ stream and show tokens in chat UI.
- When response contains "Ready to generate" â†’ call `/api/generate`.
- Display the returned file contents or let users download them.
- *Optional*: fetch files separately via `/api/files/...` endpoints.

> âœ… Never expose the Gemini API key â€” itâ€™s server-side only.

---

## ğŸ§  Backend Dev Guide

If integrating this service into your larger backend:

- Treat it as a microservice â€” either deploy separately or as a submodule.
- Identify users by their `session_id`.
- After generation, fetch files via `/api/files/...`.
- Store them in your own database or S3.
- Redis ensures multiple instances share the same sessions.

---

## ğŸ”§ Environment Variables

| Variable             | Description                                         |
|----------------------|-----------------------------------------------------|
| GEMINI_API_KEY       | Google Gemini API key                               |
| GEMINI_CHAT_MODEL    | Model used for streaming chat (`gemini-1.5-flash`)  |
| GEMINI_GENERATE_MODEL| Model used for file generation (`gemini-2.5-pro`)   |
| REDIS_HOST           | Redis hostname                                      |
| REDIS_PORT           | Redis port (default: 6379)                          |

---

## ğŸš¨ Known Limitations (Next Fixes)

| Limitation        | Description                  | Planned Fix                        |
|-------------------|-----------------------------|------------------------------------|
| No auth           | Anyone can hit endpoints    | Add API key middleware             |
| No rate limit     | Risk of spam                | Integrate FastAPI limiter          |
| Regex-based parsing| Parsing brittle for complex output | Switch to structured Gemini output|
| Test UI           | Very basic HTML             | Replace with modern chat UI        |


---

## ğŸ’¡ Design Philosophy

- **Contract-First** â†’ No code before API spec
- **Deterministic AI** â†’ Same inputs â†’ same artifacts
- **Decoupled architecture** â†’ Chat, generation, parsing, and storage are modular
- **Production-focused** â†’ Redis-backed, scalable, and clean
- **Developer-friendly** â†’ Explicit, predictable, and minimal surprises

---

## ğŸ§° Example Integration Flow

```
Frontend Chat â†’ /api/chat/stream
          â†“
    Bot asks clarifying questions
          â†“
    User types "GENERATE"
          â†“
    Backend calls /api/generate
          â†“
    Files stored & parsed into Redis
          â†“
    Frontend fetches /api/files/{session_id}/...
          â†“
    ğŸ‰ Display or export artifacts
```